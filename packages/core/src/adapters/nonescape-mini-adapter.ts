import type { MlModelRunner } from '../types.js';
import { registerMlModel } from '../detectors/image-detector.js';

export interface NonescapeModelApi {
  predict(input: {
    data: Uint8ClampedArray;
    width: number;
    height: number;
    features: NonescapeModelFeatures;
  }): number | Promise<number>;
}

export interface NonescapeModelFeatures {
  meanSat: number;
  satVar: number;
  meanLum: number;
  channelVarSimilarity: number;
  /** Mean luminance gradient magnitude (per-pixel rate, 0–1). Lower = smoother = more AI-like. */
  gradientMean: number;
  /** Population variance of luminance values (0–~0.25). */
  lumVariance: number;
  /**
   * Mean luminance variance in the flattest 20% of 8×8 blocks.
   * Diffusion models fully denoise, leaving near-zero variance in smooth regions.
   * Real JPEG photos retain JPEG block artifacts + sensor noise (higher floor).
   * Reference: Corvi et al., "On the Detection of Synthetic Images Generated by
   *   Diffusion Models" (ICASSP 2023).
   */
  noiseFloor: number;
  /**
   * Coefficient of variation (std/mean) of 8×8-block luminance variances.
   * Real photos: high CoV from depth-of-field and motion blur diversity.
   * AI images: spatially uniform quality → low CoV.
   * Reference: Simoncelli & Olshausen, "Natural image statistics and neural
   *   representation" (Annu. Rev. Neurosci. 2001).
   */
  textureCoV: number;
  /**
   * Fraction of stride-sampled interior pixels with near-zero discrete Laplacian
   * (5-tap cross: |4I₀ − I_L − I_R − I_U − I_D| ≤ threshold).
   * AI diffusion outputs are smooth → dense near-zero Laplacian → high sparsity.
   * Real photos carry sensor noise that fills in the residual distribution.
   * Reference: Fridrich & Kodovsky, "Rich Models for Steganalysis of Digital
   *   Images" (IEEE TIFS 2012); Matern et al., "Exploiting Visual Artifacts to
   *   Expose Deepfakes and Face Manipulations" (WACV 2019).
   */
  laplacianSparsity: number;
  /**
   * Ratio of DCT high-frequency energy to total AC energy in sampled 8×8 blocks.
   * Computed using a full 2-D 8×8 DCT (Loeffler et al. 1989 / AAN algorithm).
   *
   * Diffusion models apply iterative denoising which suppresses high-frequency
   * content and noise residuals in flat regions.  Real photographs retain
   * sensor read-noise whose energy is spread across all DCT frequencies.
   * → AI images: lower dctHighFreqRatio.
   * → Real photos: higher dctHighFreqRatio (noise floor across all ACs).
   *
   * Reference: Gragnaniello et al., "Are GAN Generated Images Easy to Detect?
   *   A Critical Analysis of the State of the Art" (ICME 2021).
   */
  dctHighFreqRatio: number;
}

export interface NonescapeMiniAdapterOptions {
  /** Model profile key. Defaults to 'nonescape-mini'. */
  model?: string;
  /**
   * Optional model API implementation.
   * Pass this to swap in a new bundled model runtime without changing detector code.
   */
  api?: NonescapeModelApi;
}

const DEFAULT_MODEL_NAME = 'nonescape-mini';

// ── Precomputed 8-point DCT cosine table ──────────────────────────────────────
// DCT8_COS[k][n] = cos(π·k·(2n+1)/16) for k,n ∈ {0..7}
// Computed once at module load time to avoid Math.cos in hot loops.
const DCT8_COS: readonly (readonly number[])[] = (() => {
  const table: number[][] = [];
  for (let k = 0; k < 8; k++) {
    const row: number[] = [];
    for (let n = 0; n < 8; n++) {
      // k,n ∈ [0,7] — product k*(2n+1) ≤ 7*15 = 105, well within integer precision
      row.push(Math.cos((Math.PI * k * (2 * n + 1)) / 16));
    }
    table.push(row);
  }
  return table;
})();

const builtInModels: Record<string, NonescapeModelApi> = {
  'nonescape-mini': {
    predict({ features }): number {
      // ── Derived sub-scores from new research-backed features ──────────────────

      // Gradient smoothness (1st-order): AI diffusion outputs have smooth
      // per-pixel transitions (no sensor noise). Score 1 when gradient = 0,
      // 0 when per-pixel gradient ≥ 1/16.
      const gradSmoothnessScore = Math.max(0, 1 - features.gradientMean * 16);

      // Luminance variance: AI images tend to have moderate exposure range.
      // Very high lum variance (> 0.14) is more common in high-contrast real photos.
      const lumVarScore = Math.max(0, 1 - Math.max(0, features.lumVariance - 0.04) / 0.10);

      // Noise floor (Corvi et al. 2023): variance of flat blocks.
      // AI: near-zero (<0.0002); real JPEG: ≥0.0008 (JPEG quant noise + sensor).
      // Score: 1 when noiseFloor ≈ 0, 0 when noiseFloor ≥ 0.0010.
      const noiseFloorScore = Math.max(0, 1 - features.noiseFloor / 0.0010);

      // Texture CoV (Simoncelli & Olshausen 2001): spatial diversity of texture.
      // Real photos: depth-of-field gives CoV ≈ 2–6. AI: uniform CoV ≈ 0.3–1.5.
      // Score: 1 when CoV = 0, 0 when CoV ≥ 2.0.
      const textureUniformityScore = Math.max(0, 1 - features.textureCoV / 2.0);

      // Laplacian sparsity (Fridrich & Kodovsky 2012; Matern et al. 2019):
      // AI: sparsity ≈ 0.82–0.95 (smooth diffusion output).
      // Real photos / downscaled JPEG: sparsity ≈ 0.55–0.78 (residual noise).
      // Threshold raised from 0.65 → 0.80 so that typical downscaled real
      // photos (sparsity ≈ 0.65–0.78) do not contribute a positive score.
      // Score: 0 when sparsity ≤ 0.80, 1 when sparsity ≥ 0.95.
      const lapSparsityScore = Math.max(0, Math.min(1, (features.laplacianSparsity - 0.80) / 0.15));

      // DCT high-frequency score (Gragnaniello 2021): diffusion denoising
      // suppresses high-frequency energy.
      // AI: dctHighFreqRatio ≈ 0–0.05. Real photos (even downscaled): ≈ 0.08–0.25.
      // Threshold lowered from 0.20 → 0.08 (lower bound for downscaled real
      // photos) so only genuine AI smoothness (ratio < 0.08) fires this feature.
      const dctSmoothScore = Math.max(0, 1 - features.dctHighFreqRatio / 0.08);

      // ── Logistic regression ──────────────────────────────────────────────────
      // Bias recalibrated to -6.80 to prevent false positives on typical
      // downscaled real photos.  Root cause: the noise-sensitive features
      // (noiseFloor, laplacianSparsity, dctHighFreqRatio) also fire on real
      // photos that have been downscaled (downscaling removes sensor noise
      // and JPEG quantisation noise, making real photos look AI-smooth at
      // small resolutions).  The bias must offset the sum of all features
      // that fire on typical downscaled real photos (~4.3–5.7) so that the
      // decision boundary lies between them and clear AI outputs (~5.8–7.2).
      const linear =
        -6.80 +
        features.meanSat * 2.6 +
        (1 - features.satVar * 8) * 1.2 +
        (1 - Math.abs(features.meanLum - 0.5) * 2) * 0.9 +
        features.channelVarSimilarity * 0.7 +
        gradSmoothnessScore * 0.8 +
        lumVarScore * 0.4 +
        noiseFloorScore * 1.0 +
        textureUniformityScore * 0.6 +
        lapSparsityScore * 0.7 +
        dctSmoothScore * 0.8;         // new: DCT high-freq energy (Gragnaniello 2021)
      const score = 1 / (1 + Math.exp(-linear));
      return Math.max(0, Math.min(1, score));
    },
  },
};

function classifyFromScore(score: number): number {
  // Calibrate away from hard binary outputs so uncertain samples can escalate
  // to remote ML in the cascade. Keep strong confidence near edges.
  if (score >= 0.9) return 0.95;
  if (score <= 0.1) return 0.05;
  return Math.max(0, Math.min(1, score));
}

/** BT.601 luminance in the 0–255 range from raw RGBA pixel offset `i`. */
function luma255(data: Uint8ClampedArray, i: number): number {
  return (data[i] * 299 + data[i + 1] * 587 + data[i + 2] * 114) / 1000;
}

/**
 * Compute a 2-D 8×8 DCT on a flat 64-element luminance block (values 0–255)
 * and return the ratio of high-frequency AC energy to total AC energy.
 *
 * @param block Exactly 64 luminance values in row-major order (index = row*8+col).
 *
 * Frequency zone classification (by diagonal index k+l):
 *   low-freq  AC: k+l ∈ [1,  4] (coarse detail)
 *   mid-freq  AC: k+l ∈ [5,  8] (medium detail)
 *   high-freq AC: k+l ∈ [9, 14] (fine detail + noise)
 *
 * Returns high_AC / total_AC, or 0 if the block is constant.
 */
function blockDctHighFreqRatio(block: number[]): number {
  // Row-wise 1-D DCT
  const tmp: number[][] = [];
  for (let r = 0; r < 8; r++) {
    const row: number[] = [];
    for (let k = 0; k < 8; k++) {
      let s = 0;
      const cos_k = DCT8_COS[k];
      for (let n = 0; n < 8; n++) s += block[r * 8 + n] * cos_k[n];
      row.push(s);
    }
    tmp.push(row);
  }

  // Column-wise 1-D DCT → final 2-D DCT coefficients
  let totalAC = 0, highAC = 0;
  for (let c = 0; c < 8; c++) {
    for (let k = 0; k < 8; k++) {
      let s = 0;
      const cos_k = DCT8_COS[k];
      for (let n = 0; n < 8; n++) s += tmp[n][c] * cos_k[n];
      const diag = k + c;
      if (diag === 0) continue; // skip DC
      const e = s * s;
      totalAC += e;
      if (diag >= 9) highAC += e;
    }
  }
  return totalAC > 0 ? highAC / totalAC : 0;
}

function extractFeatures(data: Uint8ClampedArray, width: number, height: number): NonescapeModelFeatures {
  const pixelCount = data.length / 4;
  if (pixelCount === 0) {
    return {
      meanSat: 0, satVar: 0, meanLum: 0, channelVarSimilarity: 0,
      gradientMean: 0, lumVariance: 0, noiseFloor: 0, textureCoV: 0,
      laplacianSparsity: 0, dctHighFreqRatio: 0,
    };
  }

  let satSum = 0;
  let satSqSum = 0;
  let lumSum = 0;
  let lumSqSum = 0;
  let rSum = 0, gSum = 0, bSum = 0;
  let rSqSum = 0, gSqSum = 0, bSqSum = 0;

  for (let i = 0; i < data.length; i += 4) {
    const r8 = data[i], g8 = data[i + 1], b8 = data[i + 2];
    const r = r8 / 255, g = g8 / 255, b = b8 / 255;

    const max = Math.max(r, g, b);
    const sat = max === 0 ? 0 : (max - Math.min(r, g, b)) / max;
    satSum += sat;
    satSqSum += sat * sat;
    const lum = r * 0.299 + g * 0.587 + b * 0.114;
    lumSum += lum;
    lumSqSum += lum * lum;

    rSum += r8; gSum += g8; bSum += b8;
    rSqSum += r8 * r8; gSqSum += g8 * g8; bSqSum += b8 * b8;
  }

  const meanSat = satSum / pixelCount;
  const satVar = Math.max(0, satSqSum / pixelCount - meanSat * meanSat);
  const meanLum = lumSum / pixelCount;
  const lumVariance = Math.max(0, lumSqSum / pixelCount - meanLum * meanLum);

  const rMean = rSum / pixelCount;
  const gMean = gSum / pixelCount;
  const bMean = bSum / pixelCount;
  const rVar = Math.max(0, rSqSum / pixelCount - rMean * rMean);
  const gVar = Math.max(0, gSqSum / pixelCount - gMean * gMean);
  const bVar = Math.max(0, bSqSum / pixelCount - bMean * bMean);
  const varMean = (rVar + gVar + bVar) / 3;
  const channelVarSimilarity =
    varMean > 0
      ? Math.max(
          0,
          Math.min(
            1,
            1 -
              (Math.abs(rVar - varMean) + Math.abs(gVar - varMean) + Math.abs(bVar - varMean)) /
                (3 * varMean)
          )
        )
      : 1;

  // Gradient mean: mean per-pixel luminance gradient magnitude.
  // Stride-sampled to cap computation at ≈128×128 points regardless of image size,
  // then divided by stride to obtain a per-pixel rate comparable across resolutions.
  const gStride = Math.max(1, Math.ceil(Math.max(width, height) / 128));
  let gradSum = 0;
  let gradCount = 0;
  for (let y = 0; y < height - gStride; y += gStride) {
    for (let x = 0; x < width - gStride; x += gStride) {
      const i0 = (y * width + x) * 4;
      const i1 = (y * width + x + gStride) * 4;       // right neighbour
      const i2 = ((y + gStride) * width + x) * 4;    // bottom neighbour
      // Luminance in 0–255 range via BT.601 helper
      const l0 = luma255(data, i0);
      const l1 = luma255(data, i1);
      const l2 = luma255(data, i2);
      // Divide by: 2 (average two directions) × gStride (per-pixel rate) × 255 (→ [0,1])
      gradSum += (Math.abs(l1 - l0) + Math.abs(l2 - l0)) / (2 * gStride * 255);
      gradCount++;
    }
  }
  const gradientMean = gradCount > 0 ? gradSum / gradCount : 0;

  // ── Block-based texture analysis ──────────────────────────────────────────
  // Divide image into 8×8 blocks; stride-sample block origins to ≈64×64 grid.
  // Block luminance is normalised to [0,1] so variances are directly comparable.
  const BLK = 8;
  const blkStep = Math.max(BLK, Math.ceil(Math.max(width, height) / 64) * BLK);
  const blockVars: number[] = [];

  for (let by = 0; by + BLK <= height; by += blkStep) {
    for (let bx = 0; bx + BLK <= width; bx += blkStep) {
      let bLumSum = 0, bLumSqSum = 0;
      const bN = BLK * BLK;
      for (let dy = 0; dy < BLK; dy++) {
        for (let dx = 0; dx < BLK; dx++) {
          const i = ((by + dy) * width + (bx + dx)) * 4;
          const lv = luma255(data, i) / 255; // normalised to [0,1]
          bLumSum += lv;
          bLumSqSum += lv * lv;
        }
      }
      const bMean = bLumSum / bN;
      blockVars.push(Math.max(0, bLumSqSum / bN - bMean * bMean));
    }
  }

  // noiseFloor: mean variance of the smoothest 20% of blocks.
  // AI diffusion models remove all noise → near-zero flat-block variance.
  // Real JPEG photos retain quantisation noise → higher floor.
  let noiseFloor = 0;
  if (blockVars.length > 0) {
    const sorted = blockVars.slice().sort((a, b) => a - b);
    const nFlat = Math.max(1, Math.floor(sorted.length * 0.20));
    noiseFloor = sorted.slice(0, nFlat).reduce((a, b) => a + b, 0) / nFlat;
  }

  // textureCoV: coefficient of variation of block variances.
  // Low CoV = spatially uniform texture = more AI-like.
  // Guard: require meaningful mean block variance (> 1e-4 on 0–1 lum scale) so
  // that solid-colour inputs don't get CoV = 0 due to floating-point rounding.
  let textureCoV = 0;
  if (blockVars.length > 1) {
    const bvMean = blockVars.reduce((a, b) => a + b, 0) / blockVars.length;
    if (bvMean > 1e-4) {
      const bvVar = blockVars.reduce((a, b) => a + (b - bvMean) ** 2, 0) / blockVars.length;
      textureCoV = Math.sqrt(bvVar) / bvMean;
    }
  }

  // Laplacian sparsity: fraction of stride-sampled interior pixels whose
  // 5-tap discrete Laplacian magnitude is ≤ lapThreshold (0–255 scale).
  // AI diffusion outputs → smooth → high sparsity.
  // Real photos → sensor noise fills residual distribution → lower sparsity.
  // Threshold scales with stride so the per-pixel noise floor is consistent.
  const lapStride = Math.max(1, Math.ceil(Math.max(width, height) / 256));
  const lapThreshold = 5 * lapStride; // ≈ sensor noise floor scaled to stride
  let lapSparse = 0, lapCount = 0;
  for (let y = lapStride; y < height - lapStride; y += lapStride) {
    for (let x = lapStride; x < width - lapStride; x += lapStride) {
      const i0 = (y * width + x) * 4;
      const iL = (y * width + x - lapStride) * 4;
      const iR = (y * width + x + lapStride) * 4;
      const iU = ((y - lapStride) * width + x) * 4;
      const iD = ((y + lapStride) * width + x) * 4;
      // Luminance in 0–255 range via BT.601 helper
      const l0 = luma255(data, i0);
      const lL = luma255(data, iL);
      const lR = luma255(data, iR);
      const lU = luma255(data, iU);
      const lD = luma255(data, iD);
      // 5-tap cross Laplacian: L = 4·I₀ − I_L − I_R − I_U − I_D
      if (Math.abs(4 * l0 - lL - lR - lU - lD) <= lapThreshold) lapSparse++;
      lapCount++;
    }
  }
  const laplacianSparsity = lapCount > 0 ? lapSparse / lapCount : 0;

  // DCT high-frequency energy ratio.
  // Sample 8×8 blocks at ≈64×64 grid; compute blockDctHighFreqRatio() for each
  // and average the results.  Blocks with zero AC energy are skipped (solid colour).
  const DCT_BLK = 8;
  const dctStep = Math.max(DCT_BLK, Math.ceil(Math.max(width, height) / 64) * DCT_BLK);
  let dctRatioSum = 0, dctRatioCount = 0;
  const dctBlock: number[] = new Array(64);
  for (let by = 0; by + DCT_BLK <= height; by += dctStep) {
    for (let bx = 0; bx + DCT_BLK <= width; bx += dctStep) {
      for (let dy = 0; dy < DCT_BLK; dy++) {
        for (let dx = 0; dx < DCT_BLK; dx++) {
          dctBlock[dy * DCT_BLK + dx] = luma255(data, ((by + dy) * width + (bx + dx)) * 4);
        }
      }
      dctRatioSum += blockDctHighFreqRatio(dctBlock);
      dctRatioCount++;
    }
  }
  const dctHighFreqRatio = dctRatioCount > 0 ? dctRatioSum / dctRatioCount : 0;

  return {
    meanSat, satVar, meanLum, channelVarSimilarity,
    gradientMean, lumVariance, noiseFloor, textureCoV, laplacianSparsity,
    dctHighFreqRatio,
  };
}

function resolveModelApi(options: NonescapeMiniAdapterOptions): NonescapeModelApi {
  if (options.api) return options.api;
  const selectedModel = options.model ?? DEFAULT_MODEL_NAME;
  return builtInModels[selectedModel] ?? builtInModels[DEFAULT_MODEL_NAME];
}

export function createNonescapeMiniRunner(
  options: NonescapeMiniAdapterOptions = {}
): MlModelRunner {
  const modelApi = resolveModelApi(options);

  return {
    async run(data: Uint8ClampedArray, width: number, height: number): Promise<number> {
      const features = extractFeatures(data, width, height);
      const rawScore = await modelApi.predict({ data, width, height, features });
      return classifyFromScore(Math.max(0, Math.min(1, rawScore)));
    },
  };
}

export function registerNonescapeMiniModel(options: NonescapeMiniAdapterOptions = {}): void {
  registerMlModel(createNonescapeMiniRunner(options));
}
